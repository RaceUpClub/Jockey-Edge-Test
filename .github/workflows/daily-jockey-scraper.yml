name: Daily Jockey Scraper

on:
  schedule:
    - cron: '0 6 * * *'        # Täglich 6:00 UTC ≈ 7 Uhr MEZ
  workflow_dispatch:           # Manueller Test

permissions:
  contents: write              # Für Datei-Commits

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Repository auschecken
        uses: actions/checkout@v4

      - name: Node.js einrichten
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Dependencies installieren (inkl. Puppeteer)
  run: npm install

      # ── Puppeteer: Chromium-Dependencies für Ubuntu ──
      - name: Puppeteer System-Pakete installieren
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            ca-certificates fonts-liberation libasound2 libatk-bridge2.0-0 \
            libatk1.0-0 libc6 libcairo2 libcups2 libdbus-1-3 libexpat1 \
            libfontconfig1 libgbm1 libgcc1 libglib2.0-0 libgtk-3-0 \
            libnspr4 libnss3 libpango-1.0-0 libpangocairo-1.0-0 \
            libstdc++6 libx11-6 libx11-xcb1 libxcb1 libxcomposite1 \
            libxcursor1 libxdamage1 libxext6 libxfixes3 libxi6 \
            libxrandr2 libxrender1 libxss1 libxtst6 lsb-release \
            wget xdg-utils

      - name: Scraper ausführen
        run: node jockey_scraper.js

      # Ergebnisse committen (CSV + JSON)
      - name: Änderungen committen & pushen
        uses: EndBug/add-and-commit@v9
        with:
          default_author: github_actions
          message: 'Daily Jockey Scrape: Update vom ${{ github.event.repository.updated_at }}'
          add: 'jockey_stats_de.*'  # Nur die Output-Dateien
